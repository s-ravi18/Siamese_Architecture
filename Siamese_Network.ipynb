{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUAHtZHEr2I2bhJ7TWr7Qw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-ravi18/Siamese_Architecture/blob/main/Siamese_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fixed Configuration;\n",
        "\n",
        "training_dir = \"/content/drive/My Drive/data/sign_data/train\"\n",
        "training_csv = \"/content/drive/My Drive/data/sign_data/train_data.csv\"\n",
        "testing_csv = \"/content/drive/My Drive/data/sign_data/test_data.csv\"\n",
        "testing_dir = \"/content/drive/My Drive/data/sign_data/test\"\n",
        "batch_size = 32\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "T5bP8T1E7AEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the constrastive loss function;\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    \"Contrastive loss function\"\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
        "            + (label)\n",
        "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "\n",
        "        return loss_contrastive\n",
        "\n",
        "\n",
        "\n",
        "def imshow(img, text=None, should_save=False):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(\n",
        "            75,\n",
        "            8,\n",
        "            text,\n",
        "            style=\"italic\",\n",
        "            fontweight=\"bold\",\n",
        "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
        "        )\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_plot(iteration, loss):\n",
        "    plt.plot(iteration, loss)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NNnjmk2E7H7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5GulJ5b8Bh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as utils, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "import os\n",
        "\n",
        "\n",
        "# load the dataset\n",
        "training_dir = training_dir\n",
        "testing_dir = testing_dir\n",
        "training_csv = training_csv\n",
        "testing_csv = testing_csv\n"
      ],
      "metadata": {
        "id": "6BA8pLd18Bkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing and loading the dataset\n",
        "class SiameseDataset:\n",
        "    def __init__(self, training_csv=None, training_dir=None, transform=None):\n",
        "        # used to prepare the labels and images path\n",
        "        self.train_df = pd.read_csv(training_csv)\n",
        "        self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n",
        "        self.train_dir = training_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # getting the image path\n",
        "        image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n",
        "        image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n",
        "\n",
        "        # Loading the image\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "\n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return (\n",
        "            img0,\n",
        "            img1,\n",
        "            torch.from_numpy(\n",
        "                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_df)"
      ],
      "metadata": {
        "id": "zSMe--HC8FgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0rdI3sGM8Glj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the the dataset from raw image folders\n",
        "siamese_dataset = SiameseDataset(\n",
        "    training_csv,\n",
        "    training_dir,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "1xxD_vg28Gnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the sample of images and to check whether its loading properly\n",
        "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "\n",
        "example_batch = next(dataiter)\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "\n",
        "print(example_batch[2].numpy())"
      ],
      "metadata": {
        "id": "tkHOhzz18Fih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSqkxBXh8RDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a siamese network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "        )\n",
        "\n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.5),\n",
        "\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128,2))\n",
        "\n",
        "\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # Forward pass\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "NcLoYeNM8RGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset as pytorch tensors using dataloader\n",
        "train_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "_WQMC4ny8VQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare Siamese Network\n",
        "net = SiameseNetwork().cuda()\n",
        "# Declare Loss Function\n",
        "criterion = ContrastiveLoss()\n",
        "# Declare Optimizer\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)"
      ],
      "metadata": {
        "id": "dUMtEwQ28W1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zCTxxsOg8a4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WduPL_yA63S-"
      },
      "outputs": [],
      "source": [
        "#train the model\n",
        "def train(train_dataloader):\n",
        "    loss=[]\n",
        "    counter=[]\n",
        "    iteration_number = 0\n",
        "    for i, data in enumerate(train_dataloader,0):\n",
        "      img0, img1 , label = data\n",
        "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      output1,output2 = net(img0,img1)\n",
        "      loss_contrastive = criterion(output1,output2,label)\n",
        "      loss_contrastive.backward()\n",
        "      optimizer.step()\n",
        "      loss.append(loss_contrastive.item())\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean()/len(train_dataloader)\n",
        "\n",
        "\n",
        "def eval(eval_dataloader):\n",
        "    loss=[]\n",
        "    counter=[]\n",
        "    iteration_number = 0\n",
        "    for i, data in enumerate(eval_dataloader,0):\n",
        "      img0, img1 , label = data\n",
        "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "      output1,output2 = net(img0,img1)\n",
        "      loss_contrastive = criterion(output1,output2,label)\n",
        "      loss.append(loss_contrastive.item())\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean()/len(eval_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODHeR97B80-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset\n",
        "test_dataset = SiameseDataset(\n",
        "    training_csv=testing_csv,\n",
        "    training_dir=testing_dir,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
        "    ),\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, num_workers=6, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "DGKMfwaN80Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,epochs):\n",
        "  best_eval_loss = 9999\n",
        "  train_loss = train(train_dataloader)\n",
        "  eval_loss = eval(test_dataloader)\n",
        "\n",
        "  print(f\"Training loss{train_loss}\")\n",
        "  print(\"-\"*20)\n",
        "  print(f\"Eval loss{eval_loss}\")\n",
        "\n",
        "  if eval_loss<best_eval_loss:\n",
        "    best_eval_loss = eval_loss\n",
        "    print(\"-\"*20)\n",
        "    print(f\"Best Eval loss{best_eval_loss}\")\n",
        "    torch.save(net.state_dict(), \"/content/model.pth\")\n",
        "    print(\"Model Saved Successfully\")"
      ],
      "metadata": {
        "id": "l-5v9F4v68wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vD7Ka-458l9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, data in enumerate(test_dataloader, 0):\n",
        "    x0, x1, label = data\n",
        "    concat = torch.cat((x0, x1), 0)\n",
        "    output1, output2 = model(x0.to(device), x1.to(device))\n",
        "\n",
        "    eucledian_distance = F.pairwise_distance(output1, output2)\n",
        "\n",
        "    if label == torch.FloatTensor([[0]]):\n",
        "        label = \"Original Pair Of Signature\"\n",
        "    else:\n",
        "        label = \"Forged Pair Of Signature\"\n",
        "\n",
        "    imshow(torchvision.utils.make_grid(concat))\n",
        "    print(\"Predicted Eucledian Distance:-\", eucledian_distance.item())\n",
        "    print(\"Actual Label:-\", label)\n",
        "    count = count + 1\n",
        "    if count == 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "hKhN0cEi685s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}